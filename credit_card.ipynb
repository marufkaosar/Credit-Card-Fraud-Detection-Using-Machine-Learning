{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8954bb-f259-4529-9bac-532392b0f1ef",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection Using Machine Learning\n",
    "Detecting credit card fraud involves using machine learning techniques to analyze transactional data and classify whether a transaction is fraudulent or not. Below is a step-by-step process and code to implement this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09500eb3-17ad-4f22-966f-a85b1ca7229f",
   "metadata": {},
   "source": [
    "## Process Explanation\n",
    "\n",
    "* Understand the Dataset:\n",
    "Use a dataset with features representing transactional data and a label indicating fraud (1) or non-fraud (0).\n",
    "Example dataset: Kaggle - Credit Card Fraud Detection.\n",
    "\n",
    "* Preprocessing:\n",
    "Handle class imbalance (fraudulent transactions are rare).\n",
    "Normalize/scale features for better model performance.\n",
    "\n",
    "* Train-Test Split:\n",
    "Split the data into training and testing datasets.\n",
    "\n",
    "* Model Selection:\n",
    "Use a classification model such as Logistic Regression, Random Forest, or XGBoost.\n",
    "\n",
    "* Evaluation:\n",
    "Evaluate using metrics like accuracy, precision, recall, and the F1 score.\n",
    "Use a confusion matrix to assess model performance on imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "50621cbe-cd04-40ae-af4c-4ee04ce8f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d4c7005-2f26-4f05-85fc-e761223c29d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/kaosarahmed/Documents/Data Analysis/Credit Card Fraud Detection Using Machine Learning/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93eaebc8-e563-4fca-9305-e3c459de67d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "477afe40-abac-42bb-b3f7-dc8d22fa7212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03420891-afba-4702-8ccb-37d3f9487603",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None # To show all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0589f3b5-2a8a-4987-9a2a-26bda8625539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aae7782a-ae55-4ded-9fde-86b5ada80ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0183c9ca-3e87-4599-ad40-dbbe4262100a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Columns: 31\n",
      "Number of Rows: 284807\n"
     ]
    }
   ],
   "source": [
    "print('Number of Columns: {}'. format(df.shape[1]))\n",
    "print('Number of Rows: {}'. format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9bb4ce5-2fab-4352-99aa-7665237ea841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87f3e385-220f-4161-bd1d-77126487e4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() #Checking the null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3d871-47b7-4054-9ef9-6a1ce4abf500",
   "metadata": {},
   "source": [
    "## Why I Choose the Credit Card Fraud Detection Dataset?\n",
    "The credit card fraud detection dataset is an excellent choice for building a data science project due to several reasons:\n",
    "\n",
    "### Choosing this dataset allows you to showcase:\n",
    "\n",
    "* Real-world problem-solving.\n",
    "* Handling imbalanced datasets.\n",
    "* Expertise in machine learning and evaluation metrics.\n",
    "* Applicability of skills in the financial and banking sectors.\n",
    "* \n",
    "This project not only builds technical skills but also demonstrates your understanding of business value, making it a standout addition to my portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a5dd03-7cfc-4f40-8581-ff3d1cebbce9",
   "metadata": {},
   "source": [
    "## Why Scale the Amount Column?\n",
    "* Normalization of Features:\n",
    "\n",
    "* The Amount column represents monetary values and typically has a wide range of values (e.g., $1 to thousands of dollars).\n",
    "Other features (V1, V2, ..., V28) in the dataset are already PCA-transformed and centered around zero with a small range of values.\n",
    "\n",
    "* Without scaling, the Amount column could dominate the model due to its larger range, leading to biased results.\n",
    "Improving Model Convergence:\n",
    "\n",
    "* Many machine learning algorithms (e.g., logistic regression, SVM, neural networks) are sensitive to the scale of input features.\n",
    "\n",
    "* Scaling helps models converge faster during training and can improve overall performance.\n",
    "Uniform Contribution:\n",
    "\n",
    "By scaling, I can ensure that the Amount column contributes equally to the predictions as the other features, avoiding disproportionate influence.\n",
    "\n",
    "## When to Scale?\n",
    "* Before Training: Always scale features as part of preprocessing, right after splitting the dataset into training and testing sets.\n",
    "\n",
    "### Scaler Choice:\n",
    "* StandardScaler: Useful for standardization (mean = 0, standard deviation = 1), commonly used for algorithms that assume a Gaussian distribution.\n",
    "* MinMaxScaler: Scales data to a range (e.g., 0 to 1) and is useful for algorithms like neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3e5984f-9bcf-432e-8955-9137ae0d3f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "842dc175-f729-4499-9838-fb4b0fad10ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "df['Amount'] = sc.fit_transform(pd.DataFrame(df['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a838b6a-112a-4888-a87c-1fb34331747d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6193b6a-4c9f-4d36-b1d2-cf32e800df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e47ad73e-94a5-494e-bb66-3d6856881f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6558f1e0-7e7d-4c6b-b3ad-3f3fb9ea7e40",
   "metadata": {},
   "source": [
    "* To check for duplicate values in a dataset, we can use the .duplicated() method in pandas. Here’s how to check for duplicates in the credit card fraud detection dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4722b5a-edff-40e1-8f6c-71c0c89a4caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8aca5e60-06ea-47db-849d-98d05a2a907f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9144"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84aee09d-e510-4ecf-a649-cb58404b80e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4fab883-175f-4547-b031-d5a0dc68d345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 30)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92300dfc-b546-44b7-8d13-59e755492815",
   "metadata": {},
   "source": [
    "## Check Class Imbalance\n",
    "\n",
    "To check for imbalance in a dataset, We typically examine the distribution of the target variable (e.g., the \"Class\" column in the credit card fraud detection dataset). Here's how we can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b42435f-b934-4790-a77c-bf87d8a559b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1       473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "64501dc2-82e3-47c5-ac08-ed80a732e6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "Class\n",
      "0    275190\n",
      "1       473\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class percentage distribution:\n",
      "Class\n",
      "0    99.828414\n",
      "1     0.171586\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Check the distribution of the target variable\n",
    "class_distribution = df['Class'].value_counts()\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(class_distribution)\n",
    "\n",
    "# Calculate the percentage distribution\n",
    "class_percentage = df['Class'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\nClass percentage distribution:\")\n",
    "print(class_percentage)\n",
    "\n",
    "# Visualize the imbalance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_distribution.plot(kind='bar', color=['blue', 'red'])\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=[0, 1], labels=['Non-Fraud (0)', 'Fraud (1)'], rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f456f-ce09-486c-b04d-7112258c8a57",
   "metadata": {},
   "source": [
    "It shows that higly imbalance data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3318fe4d-1edc-4c37-afe8-4a0ed879fd1f",
   "metadata": {},
   "source": [
    "## Splitting Dataset\n",
    "\n",
    "### train_test_split Parameters:\n",
    "\n",
    "* X: Feature set (all columns except the target).\n",
    "* y: Target variable (Class in this case).\n",
    "* test_size=0.2: Allocates 20% of the data for testing and 80% for training.\n",
    "* random_state=42: Ensures reproducibility of results.\n",
    "* stratify=y: Ensures the proportion of fraud and non-fraud cases is maintained in both training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a61b8c57-62a1-467f-98c2-f795a53d289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis = 1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a8391a3-89a6-465d-ad42-594160e2d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9043d625-c189-4b5f-a9ca-e602b4169e68",
   "metadata": {},
   "source": [
    "## Handle Imbalanced Datasets\n",
    "* In cases like credit card fraud detection, where fraudulent transactions are rare, accuracy can be misleading (e.g., predicting \"non-fraud\" for all instances would give high accuracy but miss all fraud cases).\n",
    "* Metrics like precision, recall, and F1 score are better suited to evaluate performance on imbalanced datasets.\n",
    "\n",
    "### A dictionary Classifier is created where:\n",
    "* Keys are the names of the classifiers ('Logistic Regression', 'Decision Tree Classifier').\n",
    "* Values are instances of the corresponding classifiers (LogisticRegression() and DecisionTreeClassifier()).\n",
    "\n",
    "### The for loop iterates over the dictionary:\n",
    "* name: The name of the classifier (e.g., 'Logistic Regression').\n",
    "* clf: The classifier object (e.g., LogisticRegression()).\n",
    "\n",
    "* Prints a header for each classifier to distinguish its results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f40a909c-438d-4984-84f5-441e4b0f6f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\='\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\='\n",
      "/var/folders/x5/q2mtrpyd1g5d_qn33yggj7y40000gn/T/ipykernel_1243/3091901080.py:7: SyntaxWarning: invalid escape sequence '\\='\n",
      "  print(f\"\\======={name}=======\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\=======Logistic Regression=======\n",
      "\n",
      " Accuracy : 0.9992563437505668\n",
      "\n",
      " Precision : 0.890625\n",
      "\n",
      " Recall : 0.6263736263736264\n",
      "\n",
      " F1 Score : 0.7354838709677419\n",
      "\\=======Decision Tree Classifier=======\n",
      "\n",
      " Accuracy : 0.9989298605191084\n",
      "\n",
      " Precision : 0.6666666666666666\n",
      "\n",
      " Recall : 0.7032967032967034\n",
      "\n",
      " F1 Score : 0.6844919786096256\n"
     ]
    }
   ],
   "source": [
    "Classifier = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in Classifier.items():\n",
    "    print(f\"\\======={name}=======\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n Accuracy : {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n Precision : {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n Recall : {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n F1 Score : {f1_score(y_test, y_pred)}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aac0e7-b8c2-4831-9639-ee76f5a82053",
   "metadata": {},
   "source": [
    "### Calculates and prints the following evaluation metrics:\n",
    "* Accuracy: The proportion of correct predictions out of all predictions.\n",
    "* Precision: The proportion of true positive predictions out of all positive predictions.\n",
    "* Recall: The proportion of true positive predictions out of all actual positives.\n",
    "* F1 Score: The harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d1899-0dbc-4880-92a1-a0e84f71910a",
   "metadata": {},
   "source": [
    "## Undersampling the Majority Class\n",
    "* Reduces the size of the majority class by removing some instances.\n",
    "* Useful when the dataset is large, but it may result in losing valuable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "abea268d-3903-4108-a6b2-0b1217634b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = df[df['Class']==0]\n",
    "fraud = df[df['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "631a5e18-82e2-404c-a45b-36fe4ae608a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275190, 30)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "50b3aca6-5371-420d-98b2-ec921afba748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "88fac6b1-f4c0-4d6e-abac-08b98cc11345",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sample = normal.sample(n = 473)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5dde0982-61c2-4802-8e06-45f041868c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4b5c6c5d-818c-4993-ab2d-a87906fe1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([normal_sample, fraud], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6c30061e-13ef-4f98-98c3-17bf0a622c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.038552</td>\n",
       "      <td>0.181143</td>\n",
       "      <td>-1.845811</td>\n",
       "      <td>0.636579</td>\n",
       "      <td>0.532613</td>\n",
       "      <td>-0.638957</td>\n",
       "      <td>0.109594</td>\n",
       "      <td>-0.230747</td>\n",
       "      <td>0.628839</td>\n",
       "      <td>-0.725029</td>\n",
       "      <td>-0.444032</td>\n",
       "      <td>0.710861</td>\n",
       "      <td>1.126434</td>\n",
       "      <td>-1.966863</td>\n",
       "      <td>-0.462440</td>\n",
       "      <td>0.060652</td>\n",
       "      <td>1.154695</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>-0.143085</td>\n",
       "      <td>-0.070156</td>\n",
       "      <td>-0.024726</td>\n",
       "      <td>0.273913</td>\n",
       "      <td>0.046953</td>\n",
       "      <td>0.567931</td>\n",
       "      <td>0.153321</td>\n",
       "      <td>0.611084</td>\n",
       "      <td>-0.034791</td>\n",
       "      <td>-0.021816</td>\n",
       "      <td>-0.325283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.753389</td>\n",
       "      <td>-0.525593</td>\n",
       "      <td>0.531435</td>\n",
       "      <td>1.380020</td>\n",
       "      <td>-0.903942</td>\n",
       "      <td>-0.071588</td>\n",
       "      <td>-0.099976</td>\n",
       "      <td>0.966364</td>\n",
       "      <td>-0.719864</td>\n",
       "      <td>-0.370219</td>\n",
       "      <td>0.504297</td>\n",
       "      <td>0.440595</td>\n",
       "      <td>-0.254636</td>\n",
       "      <td>0.998771</td>\n",
       "      <td>0.836125</td>\n",
       "      <td>0.771993</td>\n",
       "      <td>-0.369910</td>\n",
       "      <td>1.251402</td>\n",
       "      <td>0.543135</td>\n",
       "      <td>0.307708</td>\n",
       "      <td>0.368497</td>\n",
       "      <td>0.432378</td>\n",
       "      <td>-0.302330</td>\n",
       "      <td>0.035843</td>\n",
       "      <td>-0.048487</td>\n",
       "      <td>-0.254192</td>\n",
       "      <td>0.140337</td>\n",
       "      <td>-0.250703</td>\n",
       "      <td>0.566330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.903655</td>\n",
       "      <td>-1.145761</td>\n",
       "      <td>-1.667435</td>\n",
       "      <td>-0.910355</td>\n",
       "      <td>-0.304818</td>\n",
       "      <td>-0.560610</td>\n",
       "      <td>-0.122540</td>\n",
       "      <td>-0.221635</td>\n",
       "      <td>-0.829871</td>\n",
       "      <td>0.881326</td>\n",
       "      <td>1.082800</td>\n",
       "      <td>0.347423</td>\n",
       "      <td>0.214867</td>\n",
       "      <td>0.177433</td>\n",
       "      <td>-0.965105</td>\n",
       "      <td>0.745891</td>\n",
       "      <td>0.193442</td>\n",
       "      <td>-1.429797</td>\n",
       "      <td>0.997214</td>\n",
       "      <td>0.283891</td>\n",
       "      <td>0.199477</td>\n",
       "      <td>0.238327</td>\n",
       "      <td>0.067860</td>\n",
       "      <td>0.733351</td>\n",
       "      <td>-0.035467</td>\n",
       "      <td>-0.305102</td>\n",
       "      <td>-0.074652</td>\n",
       "      <td>-0.043064</td>\n",
       "      <td>0.270472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.950658</td>\n",
       "      <td>-0.537404</td>\n",
       "      <td>-0.242282</td>\n",
       "      <td>0.374776</td>\n",
       "      <td>-0.873818</td>\n",
       "      <td>-0.354543</td>\n",
       "      <td>-0.807304</td>\n",
       "      <td>0.143305</td>\n",
       "      <td>1.083520</td>\n",
       "      <td>0.242421</td>\n",
       "      <td>0.696257</td>\n",
       "      <td>0.412329</td>\n",
       "      <td>-1.105803</td>\n",
       "      <td>0.255801</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.532974</td>\n",
       "      <td>-0.643068</td>\n",
       "      <td>0.616326</td>\n",
       "      <td>-0.166244</td>\n",
       "      <td>-0.275683</td>\n",
       "      <td>0.293667</td>\n",
       "      <td>0.982426</td>\n",
       "      <td>0.141735</td>\n",
       "      <td>0.053960</td>\n",
       "      <td>-0.310386</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>-0.031018</td>\n",
       "      <td>-0.062212</td>\n",
       "      <td>-0.341275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.315674</td>\n",
       "      <td>-1.389413</td>\n",
       "      <td>-0.845852</td>\n",
       "      <td>-1.644455</td>\n",
       "      <td>-1.139027</td>\n",
       "      <td>-0.232851</td>\n",
       "      <td>-1.315687</td>\n",
       "      <td>-0.088679</td>\n",
       "      <td>-1.052065</td>\n",
       "      <td>1.537444</td>\n",
       "      <td>-1.241971</td>\n",
       "      <td>-0.790599</td>\n",
       "      <td>0.715268</td>\n",
       "      <td>-0.611897</td>\n",
       "      <td>0.020469</td>\n",
       "      <td>-0.391206</td>\n",
       "      <td>0.349736</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>-0.159846</td>\n",
       "      <td>-0.407060</td>\n",
       "      <td>-0.166877</td>\n",
       "      <td>0.050081</td>\n",
       "      <td>0.267743</td>\n",
       "      <td>0.397361</td>\n",
       "      <td>-0.228512</td>\n",
       "      <td>-0.187450</td>\n",
       "      <td>0.027118</td>\n",
       "      <td>-0.041987</td>\n",
       "      <td>-0.320445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  2.038552  0.181143 -1.845811  0.636579  0.532613 -0.638957  0.109594   \n",
       "1 -2.753389 -0.525593  0.531435  1.380020 -0.903942 -0.071588 -0.099976   \n",
       "2  1.903655 -1.145761 -1.667435 -0.910355 -0.304818 -0.560610 -0.122540   \n",
       "3  1.950658 -0.537404 -0.242282  0.374776 -0.873818 -0.354543 -0.807304   \n",
       "4  2.315674 -1.389413 -0.845852 -1.644455 -1.139027 -0.232851 -1.315687   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0 -0.230747  0.628839 -0.725029 -0.444032  0.710861  1.126434 -1.966863   \n",
       "1  0.966364 -0.719864 -0.370219  0.504297  0.440595 -0.254636  0.998771   \n",
       "2 -0.221635 -0.829871  0.881326  1.082800  0.347423  0.214867  0.177433   \n",
       "3  0.143305  1.083520  0.242421  0.696257  0.412329 -1.105803  0.255801   \n",
       "4 -0.088679 -1.052065  1.537444 -1.241971 -0.790599  0.715268 -0.611897   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0 -0.462440  0.060652  1.154695  0.009334 -0.143085 -0.070156 -0.024726   \n",
       "1  0.836125  0.771993 -0.369910  1.251402  0.543135  0.307708  0.368497   \n",
       "2 -0.965105  0.745891  0.193442 -1.429797  0.997214  0.283891  0.199477   \n",
       "3  0.010400  0.532974 -0.643068  0.616326 -0.166244 -0.275683  0.293667   \n",
       "4  0.020469 -0.391206  0.349736  0.032880 -0.159846 -0.407060 -0.166877   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.273913  0.046953  0.567931  0.153321  0.611084 -0.034791 -0.021816   \n",
       "1  0.432378 -0.302330  0.035843 -0.048487 -0.254192  0.140337 -0.250703   \n",
       "2  0.238327  0.067860  0.733351 -0.035467 -0.305102 -0.074652 -0.043064   \n",
       "3  0.982426  0.141735  0.053960 -0.310386  0.627010 -0.031018 -0.062212   \n",
       "4  0.050081  0.267743  0.397361 -0.228512 -0.187450  0.027118 -0.041987   \n",
       "\n",
       "     Amount  Class  \n",
       "0 -0.325283      0  \n",
       "1  0.566330      0  \n",
       "2  0.270472      0  \n",
       "3 -0.341275      0  \n",
       "4 -0.320445      0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0702ba7d-8b58-4029-93f8-c22b741bf7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(946, 30)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "19fc59d4-2ef1-464a-8494-3108c03d0e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    473\n",
       "1    473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ebe2e2da-7b4e-4678-b20e-a92241313622",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop('Class', axis = 1)\n",
    "y = new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "875cd6ae-8f75-4626-8e07-d7cff7fd8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "19e70391-3511-464e-b4ce-0f63d1c25d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\=======Logistic Regression=======\n",
      "\n",
      " Accuracy : 0.9473684210526315\n",
      "\n",
      " Precision : 0.9893617021276596\n",
      "\n",
      " Recall : 0.9117647058823529\n",
      "\n",
      " F1 Score : 0.9489795918367347\n",
      "\\=======Decision Tree Classifier=======\n",
      "\n",
      " Accuracy : 0.8947368421052632\n",
      "\n",
      " Precision : 0.9019607843137255\n",
      "\n",
      " Recall : 0.9019607843137255\n",
      "\n",
      " F1 Score : 0.9019607843137255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\='\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\='\n",
      "/var/folders/x5/q2mtrpyd1g5d_qn33yggj7y40000gn/T/ipykernel_1243/3091901080.py:7: SyntaxWarning: invalid escape sequence '\\='\n",
      "  print(f\"\\======={name}=======\")\n"
     ]
    }
   ],
   "source": [
    "Classifier = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in Classifier.items():\n",
    "    print(f\"\\======={name}=======\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n Accuracy : {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n Precision : {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n Recall : {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n F1 Score : {f1_score(y_test, y_pred)}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05da5a5-864c-4f1f-bed2-60e1d5b8e1c5",
   "metadata": {},
   "source": [
    "### Summary and Drawback\n",
    "After applying undersampling to balance the dataset, the performance of Logistic Regression and Decision Tree Classifier was evaluated.\n",
    "\n",
    "* Logistic Regression achieved higher accuracy (94.74%), precision (98.94%), and F1 score (94.90%), making it the stronger model overall.\n",
    "* Decision Tree Classifier delivered solid performance with a balanced recall (90.20%), making it effective for detecting fraudulent cases.\n",
    "\n",
    "### Drawback of Undersampling:\n",
    "* While undersampling balances the dataset, it removes a significant portion of the majority class, potentially leading to loss of important information. This could limit the model’s ability to generalize to unseen data in real-world scenarios where fraud is rare. \n",
    "* Alternative techniques like SMOTE (Synthetic Minority Oversampling Technique) or ensemble methods should also be explored to address this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a6a7d-924f-4041-acf4-b5aeced72f52",
   "metadata": {},
   "source": [
    "## Oversampling the Minority Class\n",
    "* Since the dataset has very few minority instances, oversampling (e.g., SMOTE) can help balance the data by generating synthetic examples of the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "10c952eb-b5b8-4d47-acb3-ae4afa004da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis = 1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3d6d993f-1b57-40a9-b240-807c4d4bafbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 29)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7ea19b51-6fbc-4990-941d-5a308408c3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b0430374-8417-4167-9f21-346957c271dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e14cd2b6-7e4a-4b92-8432-b3366ec31d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2b45714c-9810-4edd-9a8b-e475ca6cb24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1    275190\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b9cafba5-a580-473e-9b11-387195e33c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7febce15-d366-4104-8837-bcaa583dfad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\='\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\='\n",
      "/var/folders/x5/q2mtrpyd1g5d_qn33yggj7y40000gn/T/ipykernel_1243/3091901080.py:7: SyntaxWarning: invalid escape sequence '\\='\n",
      "  print(f\"\\======={name}=======\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\=======Logistic Regression=======\n",
      "\n",
      " Accuracy : 0.9447200116283295\n",
      "\n",
      " Precision : 0.9730215827338129\n",
      "\n",
      " Recall : 0.914731923713252\n",
      "\n",
      " F1 Score : 0.9429768252570025\n",
      "\\=======Decision Tree Classifier=======\n",
      "\n",
      " Accuracy : 0.9982557505723318\n",
      "\n",
      " Precision : 0.9975671308484177\n",
      "\n",
      " Recall : 0.9989455120629784\n",
      "\n",
      " F1 Score : 0.9982558456423394\n"
     ]
    }
   ],
   "source": [
    "Classifier = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in Classifier.items():\n",
    "    print(f\"\\======={name}=======\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n Accuracy : {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n Precision : {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n Recall : {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"\\n F1 Score : {f1_score(y_test, y_pred)}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71fa16a-49ed-4f22-b956-bdb7a948adc8",
   "metadata": {},
   "source": [
    "After applying oversampling, the performance metrics for the models have improved. Here's a brief summary:\n",
    "\n",
    "### Logistic Regression:\n",
    "\n",
    "* Accuracy: 94.47%\n",
    "* Precision: 97.30%\n",
    "* Recall: 91.47%\n",
    "* F1 Score: 94.30%\n",
    "\n",
    "### Decision Tree Classifier:\n",
    "\n",
    "* Accuracy: 99.83%\n",
    "* Precision: 99.76%\n",
    "* Recall: 99.89%\n",
    "* F1 Score: 99.83%\n",
    "\n",
    "The Decision Tree Classifier shows a significant improvement in accuracy and recall, making it a highly reliable model for this dataset after oversampling. On the other hand, Logistic Regression also shows a solid performance with a slight trade-off in recall but still maintains a high F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2410af09-e6ed-4eea-bd9d-6ea6630954f4",
   "metadata": {},
   "source": [
    "## Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a00f161f-4197-4805-a489-a8b20528b8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e0dbd9a4-f04b-4834-882c-5bf77161eecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6c184f89-300e-417c-aa27-9d5dcb72f345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['credit_card_model.pk1']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(dtc, 'credit_card_model.pk1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8e229d9a-f0fb-4f83-ba6c-f100cc106156",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('credit_card_model.pk1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5c2226f4-f6a2-4ef6-a423-550d79e9ff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict([[\n",
    "    0.0, -1.359807134, 1.191857111, -0.074197555, 0.003850368, 0.000595229,\n",
    "    -0.032188323, 0.001045290, -0.026200123, 0.004229349, 0.006128563, 0.002319968,\n",
    "    0.005443236, -0.004473073, -0.001743409, -0.000131130, 0.004406177, -0.002138054,\n",
    "    0.000442868, 0.002348265, -0.000322797, 0.000804261, -0.003193362, -0.001197104,\n",
    "    0.002481024, -0.003697046, 0.002695209, 0.004445698, 123.0  # Amount (29th feature)\n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "368d8456-02e1-4e5a-8999-1538eaa2dd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "66a4eb49-f320-424b-90a3-1bc70eb8a29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Transaction\n"
     ]
    }
   ],
   "source": [
    "if pred[0] == 0:\n",
    "    print('Normal Transaction')\n",
    "else:\n",
    "    print('Fraud Transaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9b9397dd-1101-4d5f-a437-fb8a511dc31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flask, streamlit >> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6f3ea-5e7a-4f93-842c-70d00ddc0503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
